{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional requirements locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade dask-labextension pandas numpy distributed dask black[jupyter] uproot3 pyarrow astropy toml numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LogNorm\n",
    "import pandas\n",
    "\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# import cdms\n",
    "import sys\n",
    "import scipy\n",
    "import random\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "\n",
    "# from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreload `cdat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdat.root import read_root_file\n",
    "from cdat.daskutils import dask_histogram, dask_histogram2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls '/cvmfs/data/CDMS/RQanalysis_testing/RQroot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding address of the files\n",
    "data_dir = \"/cvmfs/data/CDMS/RQanalysis_testing/RQroot/\"\n",
    "series_numbers = [\"25220213_171932\", \"25220214_092356\", \"25220215_073923\"]\n",
    "files = [f\"{data_dir}OFResults_{i}.root\" for i in series_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the first file to inspect structure of the dataframe\n",
    "# dask_dataframe = dd.from_map(read_root_file, files,branches=[\"*OFL*\",\"*trig*\",'*Integral*','*file*','*Midas*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask_dataframe.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "KeV_bin = {\"NFC1\": 22.9, \"NFH\": 7.1, \"NFE\": 5.7, \"NFC2\": 17.1}\n",
    "live_time = 44.85  # h\n",
    "det_mass = 0.96  # g\n",
    "\n",
    "data = dd.from_map(read_root_file, files, branches=[\"*trig_ch*\", \"*Integral*_total\"])\n",
    "trigger_ch = {\"NFC1\": 1, \"NFH\": 2, \"NFE\": 3, \"NFC2\": 4}\n",
    "# For different detectors, building histogram domains separately.\n",
    "xedges = {}\n",
    "chunk_hist = {}\n",
    "centers = {}\n",
    "bin_sizes = {}\n",
    "for det, code in trigger_ch.items():\n",
    "    if det in [\"NFC1\", \"NFC2\"]:\n",
    "        start, end = 0, 8000\n",
    "        step = (end - start) / 1000\n",
    "        xedges[det] = np.arange(start, end, step)\n",
    "    if det == \"NFH\":\n",
    "        start, end = 0, 2500\n",
    "        step = (end - start) / 1000\n",
    "        xedges[det] = np.arange(start, end, step)\n",
    "    if det == \"NFE\":\n",
    "        start, end = 0, 2000\n",
    "        step = (end - start) / 1000\n",
    "        xedges[det] = np.arange(start, end, step)\n",
    "    # Empty arrays for each channel corresponding to xedges.\n",
    "    # We fill the empty array as we iterate through the data.\n",
    "    centers[det] = (xedges[det][:-1] + xedges[det][1:]) / 2\n",
    "    bin_sizes[det] = xedges[det][1:] - xedges[det][:-1]\n",
    "\n",
    "# iterating over dets\n",
    "histograms = []\n",
    "for det, code in trigger_ch.items():\n",
    "    # Applying some inline cuts\n",
    "    subchunk = data.query(f\"trig_ch == {code}\")\n",
    "    # Filling numpy arrays for histograms.\n",
    "    histograms.append(\n",
    "        dask_histogram(\n",
    "            subchunk, f\"Integral_{det}_total\", bins=xedges[det], bins_range=None\n",
    "        )[1]\n",
    "    )\n",
    "\n",
    "histograms = da.compute(*histograms, num_workers=4)\n",
    "# turn list into dict {ch:hist[ch]}\n",
    "chunk_hist = dict(zip(centers.keys(), histograms))\n",
    "# plotting histograms.\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "for det, code in trigger_ch.items():\n",
    "    i, j = (code - 1) // 2, code % 2\n",
    "    ax[i, j].step(\n",
    "        centers[det], chunk_hist[det] / (det_mass * live_time * bin_sizes[det])\n",
    "    )\n",
    "    ax[i, j].set_xlabel(f\"Integral_{det}_total (uA)\", fontsize=20)\n",
    "    ax[i, j].set_ylabel(r\"Count/($gram.hour.bin$)\", fontsize=20)\n",
    "    ax[i, j].set_yscale(\"log\")\n",
    "    ax[i, j].tick_params(axis=\"both\", which=\"both\", labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = dd.from_map(\n",
    "    read_root_file, files, branches=[\"*OFL*\", \"*trig_ch*\", \"*Integral*_total\"]\n",
    ")\n",
    "\n",
    "trigger_ch = {\"NFC1\": 1, \"NFH\": 2, \"NFE\": 3, \"NFC2\": 4}\n",
    "KeV_bin = {\"NFC1\": 22.9, \"NFH\": 7.1, \"NFE\": 5.7, \"NFC2\": 17.1}\n",
    "auto_proc_high_energy = {\"NFE\": 0.103, \"NFH\": 0.049, \"NFC1\": 0.129, \"NFC2\": 0.0796}\n",
    "live_time = 44.85  # h\n",
    "det_mass = 0.96  # g\n",
    "\n",
    "\n",
    "# For different detectors, building histogram domains separately.\n",
    "\n",
    "xedges = {}\n",
    "yedges = {}\n",
    "\n",
    "chunk_hist = {}\n",
    "\n",
    "for det, code in trigger_ch.items():\n",
    "    if det in [\"NFC1\", \"NFC2\"]:\n",
    "        xstart, xend = 0, 900\n",
    "        xstep = (xend - xstart) / 100\n",
    "        xedges[det] = np.arange(xstart, xend, xstep)\n",
    "\n",
    "        ystart, yend = 0, 80\n",
    "        ystep = (yend - ystart) / 100\n",
    "        yedges[det] = np.arange(ystart, yend, ystep)\n",
    "\n",
    "    if det == \"NFH\":\n",
    "        xstart, xend = 0, 900\n",
    "        xstep = (xend - xstart) / 100\n",
    "        xedges[det] = np.arange(xstart, xend, xstep)\n",
    "        ystart, yend = 0, 80\n",
    "        ystep = (yend - ystart) / 100\n",
    "        yedges[det] = np.arange(ystart, yend, ystep)\n",
    "    if det == \"NFE\":\n",
    "        xstart, xend = 0, 900\n",
    "        xstep = (xend - xstart) / 100\n",
    "        xedges[det] = np.arange(xstart, xend, xstep)\n",
    "        ystart, yend = 0, 80\n",
    "        ystep = (yend - ystart) / 100\n",
    "        yedges[det] = np.arange(ystart, yend, ystep)\n",
    "\n",
    "    chunk_hist[det] = np.zeros(shape=(len(xedges[det]) - 1, len(yedges[det]) - 1))\n",
    "#     centers[det] = (xedges[det][:-1]+xedges[det][1:])/2\n",
    "#     bin_sizes = xedges[det][1:] - xedges[det][:-1]\n",
    "\n",
    "histograms = []\n",
    "\n",
    "# iterating over dets\n",
    "for det, code in trigger_ch.items():\n",
    "    # Applying some inline cuts\n",
    "    subchunk = data.query(f\"trig_ch == {code}\")\n",
    "    subchunk[f\"OFL_{det}_total_scaled\"] = (\n",
    "        subchunk.loc[:, f\"OFL_{det}_total\"] * 100 / auto_proc_high_energy[det]\n",
    "    )\n",
    "    # Filling numpy arrays for histograms.\n",
    "    ## ** (Maybe using weights inside the histogram.)\n",
    "\n",
    "    histograms.append(\n",
    "        dask_histogram2d(\n",
    "            subchunk,\n",
    "            f\"OFL_{det}_total_scaled\",\n",
    "            f\"OFL_chi2_{det}_total\",\n",
    "            bins=(xedges[det], yedges[det]),\n",
    "            bins_range=None,\n",
    "        )\n",
    "    )\n",
    "\n",
    "histograms = da.compute(*histograms)\n",
    "chunk_hist = dict(zip(xedges.keys(), histograms))\n",
    "\n",
    "real_min_c = {}\n",
    "real_max_c = {}\n",
    "min_c = {}\n",
    "max_c = {}\n",
    "for det in trigger_ch.keys():\n",
    "    real_min_c[det] = np.min(chunk_hist[det])\n",
    "    real_max_c[det] = np.max(chunk_hist[det])\n",
    "    chunk_hist[det] = scipy.signal.convolve2d(\n",
    "        chunk_hist[det], np.ones((2, 2)), mode=\"same\"\n",
    "    )\n",
    "    chunk_hist[det] = np.log(chunk_hist[det] + 1)\n",
    "    min_c[det] = np.min(chunk_hist[det])\n",
    "    max_c[det] = np.max(chunk_hist[det])\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "dets = trigger_ch.keys()\n",
    "for count in range(data.npartitions):\n",
    "    chunk = data.get_partition(count)[\n",
    "        [\"trig_ch\"]\n",
    "        + [f\"OFL_{det}_total\" for det in dets]\n",
    "        + [f\"OFL_chi2_{det}_total\" for det in dets]\n",
    "    ].compute()\n",
    "    for det, code in trigger_ch.items():\n",
    "        # For each det, we use a copy of the chunk to keep chunkes unchanged.\n",
    "        subchunk = chunk.query(f\"trig_ch == {code}\")\n",
    "        # Adjusting the copy\n",
    "        subchunk.loc[:, f\"OFL_{det}_total\"] *= 100 / auto_proc_high_energy[det]\n",
    "        i, j = (code - 1) // 2, code % 2\n",
    "        xidx = np.clip(\n",
    "            np.digitize(subchunk[f\"OFL_{det}_total\"], xedges[det]),\n",
    "            0,\n",
    "            chunk_hist[det].shape[0] - 1,\n",
    "        )\n",
    "        yidx = np.clip(\n",
    "            np.digitize(subchunk[f\"OFL_chi2_{det}_total\"], yedges[det]),\n",
    "            0,\n",
    "            chunk_hist[det].shape[1] - 1,\n",
    "        )\n",
    "        norm = plt.Normalize(min_c[det], max_c[det])\n",
    "        s = norm(chunk_hist[det][xidx, yidx])\n",
    "        c = cmap(s)\n",
    "        s = 4 / (s + 0.1)\n",
    "        # Scatter plots\n",
    "        ax[i][j] = subchunk.plot.scatter(\n",
    "            f\"OFL_{det}_total\", f\"OFL_chi2_{det}_total\", ax=ax[i, j], c=c, s=s\n",
    "        )\n",
    "\n",
    "for det, code in trigger_ch.items():\n",
    "    i, j = (code - 1) // 2, code % 2\n",
    "\n",
    "    norm = matplotlib.colors.LogNorm(real_min_c[det] + 1, real_max_c[det] + 1)\n",
    "    fig.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax[i][j])\n",
    "    ax[i, j].set_xlabel(f\"OFL_{det}_total (uA)\", fontsize=20)\n",
    "    ax[i, j].set_ylabel(f\"OFL_chi2_{det}_total (uA)\", fontsize=20)\n",
    "    ax[i, j].tick_params(axis=\"both\", which=\"both\", labelsize=15)\n",
    "    ax[i][j].set_ylim([0, 80])\n",
    "    ax[i][j].set_xlim([0, 900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** Produce the heatmap too! ******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def chi2_template(x, a, b, exp):\n",
    "    return a * x**exp + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def compute_cut(energy, chi2, trigger_ch, first_eh_peak, a, b, exp):\n",
    "    cut = np.zeros(energy[1].shape, dtype=np.bool_)\n",
    "    for i in range(len(cut)):\n",
    "        ch = trigger_ch[i]\n",
    "        if ch == 0:\n",
    "            cut[i] = 0\n",
    "        else:\n",
    "            energy_normalized = energy[ch][i] * 100 / first_eh_peak[ch]\n",
    "            cut[i] = (energy_normalized > 600) | (\n",
    "                chi2[ch][i] < chi2_template(energy_normalized, a[ch], b[ch], exp[ch])\n",
    "            )\n",
    "    return cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.typed import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = List()\n",
    "energy.append(np.array([1, 100]))\n",
    "energy.append(np.array([1, 100]))\n",
    "\n",
    "chi2 = List()\n",
    "chi2.append(np.array([1e6, 1e6]))\n",
    "chi2.append(np.array([1e6, 1e6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cut(\n",
    "    energy=energy,\n",
    "    chi2=chi2,\n",
    "    trigger_ch=np.array([0, 1]),\n",
    "    first_eh_peak=np.array([3, 4]),\n",
    "    a=np.ones(2),\n",
    "    b=np.zeros(2),\n",
    "    exp=np.ones(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chi2Cut:\n",
    "    a: dict\n",
    "    b: dict\n",
    "    exp: dict\n",
    "    trigger_ch_mapping: dict\n",
    "    first_eh_peak: dict\n",
    "    energy_limit: float = 600\n",
    "    column: str = \"OFL_{det_name}_total\"\n",
    "    column_chi2: str = \"OFL_chi2_{det_name}_total\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.max_channel_id = max(self.trigger_ch_mapping.keys())\n",
    "        for var_name in [\"a\", \"b\", \"exp\", \"first_eh_peak\"]:\n",
    "            out = np.zeros(self.max_channel_id + 1)\n",
    "            var = getattr(self, var_name)\n",
    "            for i in range(self.max_channel_id + 1):\n",
    "                if i in self.trigger_ch_mapping:\n",
    "                    out[i] = var.get(self.trigger_ch_mapping[i], var.get(\"default\"))\n",
    "            setattr(self, var_name + \"_array\", out)\n",
    "\n",
    "    def __call__(self, df):\n",
    "        df = df[df.trig_ch != 0]\n",
    "        energy = List()\n",
    "        chi2 = List()\n",
    "        for i in range(self.max_channel_id + 1):\n",
    "            if i in self.trigger_ch_mapping:\n",
    "                det_name = self.trigger_ch_mapping[i]\n",
    "                energy.append(df[self.column.format(det_name=det_name)].to_numpy())\n",
    "                chi2.append(df[self.column_chi2.format(det_name=det_name)].to_numpy())\n",
    "            else:\n",
    "                energy.append(np.zeros(1, dtype=np.float32))\n",
    "                chi2.append(np.zeros(1, dtype=np.float32))\n",
    "\n",
    "        cut = compute_cut(\n",
    "            energy=energy,\n",
    "            chi2=chi2,\n",
    "            trigger_ch=df.trig_ch.to_numpy(),\n",
    "            first_eh_peak=self.first_eh_peak_array,\n",
    "            a=self.a_array,\n",
    "            b=self.b_array,\n",
    "            exp=self.exp_array,\n",
    "        )\n",
    "        df = df.assign(chi2_cut=cut)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2cut = Chi2Cut(\n",
    "    a=dict(default=0.0005, NFE=0.00015),\n",
    "    b=dict(default=1.25),\n",
    "    exp=dict(default=2),\n",
    "    first_eh_peak={\"NFC1\": 0.129, \"NFC2\": 0.0796, \"NFH\": 0.049, \"NFE\": 0.103},\n",
    "    trigger_ch_mapping={1: \"NFC1\", 2: \"NFH\", 3: \"NFE\", 4: \"NFC2\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = dd.from_map(read_root_file, files, branches=[\"*OFL*\", \"*trig*\"])\n",
    "trigger_ch = {\"NFC1\": 1, \"NFH\": 2, \"NFE\": 3, \"NFC2\": 4}\n",
    "# Imran's work the same as Valentina's except NFH = 0.0488:\n",
    "auto_proc_high_energy = {\"NFE\": 0.103, \"NFH\": 0.049, \"NFC1\": 0.129, \"NFC2\": 0.0796}\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "data_chi2cut = data.map_partitions(chi2cut)\n",
    "# Iterating the data\n",
    "\n",
    "for det, code in trigger_ch.items():\n",
    "    # Working with subchunks to keep the main chunk unchanged.\n",
    "    subchunk = data_chi2cut.query(f\"trig_ch == {code}\").compute()\n",
    "    # define colors for passing and rejected events.\n",
    "    color = np.array([\"r\", \"b\"])[subchunk[f\"chi2_cut\"].array.astype(np.int8)]\n",
    "    # adjusting the subchunk\n",
    "    subchunk.loc[:, f\"OFL_{det}_total\"] *= 100 / auto_proc_high_energy[det]\n",
    "    i, j = (code - 1) // 2, code % 2\n",
    "    # scatter plots for each chunk\n",
    "    ax[i][j] = subchunk.plot.scatter(\n",
    "        f\"OFL_{det}_total\", f\"OFL_chi2_{det}_total\", c=color, ax=ax[i, j]\n",
    "    )\n",
    "# events passing        ax[i][j] = subchunk.plot.scatter(f'OFL_{det}_total', f'OFL_chi2_{det}_total',c =\"b\", ax = ax[i,j])\n",
    "# events not passing    ax[i][j] = subchunk.plot.scatter(f'OFL_{det}_total', f'OFL_chi2_{det}_total',c=\"r\", ax = ax[i,j])\n",
    "\n",
    "# Making plots beautiful.\n",
    "for det, code in trigger_ch.items():\n",
    "    energies = np.linspace(0, 900, 1000)\n",
    "    i, j = (code - 1) // 2, code % 2\n",
    "    ax[i, j].axvline(x=600, linewidth=2, ls=\"-.\", color=\"k\", label=\"OFL chi2 bound\")\n",
    "    ax[i][j].set_title(\n",
    "        f\"E = OFL_{det}_total*(100/{auto_proc_high_energy[det]})\", fontsize=15\n",
    "    )\n",
    "    ax[i][j].set_xlabel(f\"Energy (ev)\", fontsize=20)\n",
    "    ax[i][j].set_ylabel(f\"OFL_chi2_{det}_total (uA)\", fontsize=20)\n",
    "    ax[i][j].tick_params(axis=\"both\", which=\"both\", labelsize=15)\n",
    "    ax[i, j].legend(loc=\"upper right\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_chi2cut.chi2_cut.sum().compute()/len(data_chi2cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
